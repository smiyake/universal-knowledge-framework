#!/usr/bin/env python3
"""
çŸ¥è­˜åœ§ç¸®ãƒ¢ã‚¸ãƒ¥ãƒ¼ãƒ« - ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥è­˜ã‚’åœ§ç¸®ãƒ»è¦ç´„

Claude Codeã®ãƒˆãƒ¼ã‚¯ãƒ³ä½¿ç”¨é‡ã‚’å‰Šæ¸›ã™ã‚‹ãŸã‚ã€ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±ã‚’åŠ¹ç‡çš„ã«åœ§ç¸®ã—ã¾ã™ã€‚
"""

import os
import json
import subprocess
from pathlib import Path
from typing import Dict, List, Optional, Set, Tuple
from datetime import datetime
import yaml


class KnowledgeCompressor:
    """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥è­˜ã‚’åœ§ç¸®ãƒ»è¦ç´„ã™ã‚‹ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, config_path: Optional[Path] = None):
        """åˆæœŸåŒ–
        
        Args:
            config_path: è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¹
        """
        self.config = self._load_config(config_path)
        self.ignored_patterns = self._get_ignored_patterns()
    
    def _load_config(self, config_path: Optional[Path]) -> Dict:
        """è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        default_config = {
            "knowledge_compression": {
                "output_file": "PROJECT_KNOWLEDGE_MAP.md",
                "max_tokens": 5000,
                "update_frequency": "on_commit",
                "sections": [
                    {
                        "name": "current_state",
                        "sources": ["logs", "test_results", "docker_status"]
                    },
                    {
                        "name": "architecture",
                        "sources": ["src/", "docs/"]
                    },
                    {
                        "name": "tasks",
                        "sources": [".claude-task-cache.json", "TODO.md"]
                    }
                ],
                "claude_code_optimization": {
                    "enabled": True,
                    "priority_order": [
                        "errors_and_issues",
                        "current_tasks",
                        "recent_changes",
                        "architecture_summary"
                    ]
                }
            }
        }
        
        if config_path and config_path.exists():
            with open(config_path, 'r', encoding='utf-8') as f:
                if config_path.suffix == '.yaml' or config_path.suffix == '.yml':
                    user_config = yaml.safe_load(f)
                else:
                    user_config = json.load(f)
                
                # ãƒãƒ¼ã‚¸
                return {**default_config, **user_config}
        
        return default_config
    
    def _get_ignored_patterns(self) -> Set[str]:
        """ç„¡è¦–ã™ã‚‹ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’å–å¾—"""
        patterns = {
            '__pycache__', '.git', '.pytest_cache', 'node_modules',
            'venv', '.venv', 'env', '.env', '.mypy_cache',
            '*.pyc', '*.pyo', '.DS_Store', 'Thumbs.db'
        }
        return patterns
    
    def compress_project(self, 
                        project_path: Path,
                        max_tokens: int = 5000,
                        format: str = "claude-code") -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆå…¨ä½“ã‚’åˆ†æã—ã¦åœ§ç¸®ã•ã‚ŒãŸçŸ¥è­˜ãƒãƒƒãƒ—ã‚’ç”Ÿæˆ
        
        Args:
            project_path: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‘ã‚¹
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            format: å‡ºåŠ›ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
            
        Returns:
            åœ§ç¸®ã•ã‚ŒãŸçŸ¥è­˜ãƒãƒƒãƒ—
        """
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåˆ†æ
        state = self.analyze_project_state(project_path)
        
        # é‡è¦åº¦ã§ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        filtered = self.filter_by_importance(state, max_tokens)
        
        # ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆåˆ¥ã«å‡ºåŠ›
        if format == "claude-code":
            return self.format_for_claude_code(filtered)
        elif format == "mindmap":
            return self.format_as_mindmap(filtered)
        else:
            return self.format_as_markdown(filtered)
    
    def analyze_project_state(self, project_path: Path) -> Dict:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®ç¾åœ¨çŠ¶æ…‹ã‚’åˆ†æ
        
        Returns:
            ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹ã®è¾æ›¸
        """
        state = {
            "project_info": self._get_project_info(project_path),
            "current_errors": self._find_current_errors(project_path),
            "architecture": self._analyze_architecture(project_path),
            "recent_changes": self._get_recent_changes(project_path),
            "tasks": self._get_current_tasks(project_path),
            "dependencies": self._analyze_dependencies(project_path),
            "test_status": self._get_test_status(project_path),
            "docker_status": self._get_docker_status(project_path)
        }
        
        return state
    
    def _get_project_info(self, project_path: Path) -> Dict:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆåŸºæœ¬æƒ…å ±ã‚’å–å¾—"""
        info = {
            "name": project_path.name,
            "path": str(project_path),
            "type": self._detect_project_type(project_path)
        }
        
        # README/CLAUDE.mdã‹ã‚‰æƒ…å ±æŠ½å‡º
        for readme_name in ['CLAUDE.md', 'README.md', 'readme.md']:
            readme_path = project_path / readme_name
            if readme_path.exists():
                with open(readme_path, 'r', encoding='utf-8') as f:
                    content = f.read(1000)  # æœ€åˆã®1000æ–‡å­—
                    # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦ã‚’æŠ½å‡º
                    if 'æ¦‚è¦' in content or 'Overview' in content:
                        info['description'] = self._extract_description(content)
                    break
        
        return info
    
    def _detect_project_type(self, project_path: Path) -> str:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã‚’æ¤œå‡º"""
        # ãƒ•ã‚¡ã‚¤ãƒ«ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¿ã‚¤ãƒ—ã‚’åˆ¤å®š
        if (project_path / 'package.json').exists():
            return 'node/javascript'
        elif (project_path / 'requirements.txt').exists() or (project_path / 'pyproject.toml').exists():
            return 'python'
        elif (project_path / 'go.mod').exists():
            return 'go'
        elif (project_path / 'Cargo.toml').exists():
            return 'rust'
        elif (project_path / 'pom.xml').exists():
            return 'java/maven'
        else:
            return 'unknown'
    
    def _extract_description(self, content: str) -> str:
        """READMEã‹ã‚‰èª¬æ˜ã‚’æŠ½å‡º"""
        lines = content.split('\n')
        description_lines = []
        in_description = False
        
        for line in lines:
            if 'æ¦‚è¦' in line or 'Overview' in line:
                in_description = True
                continue
            elif in_description and line.startswith('#'):
                break
            elif in_description and line.strip():
                description_lines.append(line.strip())
        
        return ' '.join(description_lines[:3])  # æœ€åˆã®3è¡Œ
    
    def _find_current_errors(self, project_path: Path) -> List[Dict]:
        """ç¾åœ¨ã®ã‚¨ãƒ©ãƒ¼ãƒ»å•é¡Œã‚’æ¤œå‡º"""
        errors = []
        
        # ãƒ­ã‚°ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ã‚’æŠ½å‡º
        log_patterns = ['*.log', 'logs/*.log', 'test-reports/*.txt']
        for pattern in log_patterns:
            for log_file in project_path.glob(pattern):
                if log_file.is_file():
                    errors.extend(self._extract_errors_from_file(log_file))
        
        # Dockerã‚³ãƒ³ãƒ†ãƒŠã®ã‚¹ãƒ†ãƒ¼ã‚¿ã‚¹ç¢ºèª
        docker_errors = self._check_docker_errors()
        errors.extend(docker_errors)
        
        # æœ€æ–°ã®ã‚¨ãƒ©ãƒ¼ã®ã¿ä¿æŒï¼ˆé‡è¤‡æ’é™¤ï¼‰
        unique_errors = []
        seen = set()
        for error in sorted(errors, key=lambda x: x.get('timestamp', ''), reverse=True):
            key = (error['type'], error['message'][:50])
            if key not in seen:
                seen.add(key)
                unique_errors.append(error)
                if len(unique_errors) >= 10:  # æœ€å¤§10å€‹
                    break
        
        return unique_errors
    
    def _extract_errors_from_file(self, file_path: Path) -> List[Dict]:
        """ãƒ•ã‚¡ã‚¤ãƒ«ã‹ã‚‰ã‚¨ãƒ©ãƒ¼ã‚’æŠ½å‡º"""
        errors = []
        error_keywords = ['ERROR', 'FAILED', 'Exception', 'Error:', 'fail']
        
        try:
            with open(file_path, 'r', encoding='utf-8', errors='ignore') as f:
                lines = f.readlines()[-100:]  # æœ€å¾Œã®100è¡Œ
                
                for i, line in enumerate(lines):
                    for keyword in error_keywords:
                        if keyword in line:
                            errors.append({
                                'type': keyword,
                                'file': file_path.name,
                                'line': i + 1,
                                'message': line.strip()[:200],
                                'timestamp': datetime.fromtimestamp(file_path.stat().st_mtime).isoformat()
                            })
                            break
        except Exception:
            pass
        
        return errors
    
    def _check_docker_errors(self) -> List[Dict]:
        """Dockerã‚³ãƒ³ãƒ†ãƒŠã®ã‚¨ãƒ©ãƒ¼ã‚’ãƒã‚§ãƒƒã‚¯"""
        errors = []
        
        try:
            result = subprocess.run(
                ['docker', 'ps', '-a', '--format', '{{.Names}}\t{{.Status}}'],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line:
                        parts = line.split('\t')
                        if len(parts) == 2:
                            name, status = parts
                            if 'Exited' in status or 'Error' in status:
                                errors.append({
                                    'type': 'Docker',
                                    'container': name,
                                    'message': f"Container {name} is not running: {status}",
                                    'timestamp': datetime.now().isoformat()
                                })
        except Exception:
            pass
        
        return errors
    
    def _analyze_architecture(self, project_path: Path) -> Dict:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ã‚’åˆ†æ"""
        architecture = {
            'structure': self._get_directory_structure(project_path),
            'main_files': self._find_main_files(project_path),
            'services': self._detect_services(project_path),
            'databases': self._detect_databases(project_path)
        }
        
        return architecture
    
    def _get_directory_structure(self, project_path: Path, max_depth: int = 3) -> Dict:
        """ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ã‚’å–å¾—ï¼ˆé‡è¦éƒ¨åˆ†ã®ã¿ï¼‰"""
        def _build_tree(path: Path, depth: int = 0) -> Optional[Dict]:
            if depth >= max_depth:
                return None
            
            tree = {
                'name': path.name,
                'type': 'directory' if path.is_dir() else 'file',
                'children': []
            }
            
            if path.is_dir():
                # é‡è¦ãªãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªã®ã¿å±•é–‹
                important_dirs = {'src', 'app', 'api', 'services', 'components', 'tests', 'docs'}
                
                for child in sorted(path.iterdir()):
                    # ç„¡è¦–ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚¹ã‚­ãƒƒãƒ—
                    if any(pattern in str(child) for pattern in self.ignored_patterns):
                        continue
                    
                    if child.is_dir():
                        if child.name in important_dirs or depth < 2:
                            child_tree = _build_tree(child, depth + 1)
                            if child_tree:
                                tree['children'].append(child_tree)
                    elif depth < 2:  # æµ…ã„éšå±¤ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯å«ã‚ã‚‹
                        tree['children'].append({
                            'name': child.name,
                            'type': 'file'
                        })
            
            return tree
        
        return _build_tree(project_path)
    
    def _find_main_files(self, project_path: Path) -> List[Dict]:
        """ä¸»è¦ãƒ•ã‚¡ã‚¤ãƒ«ã‚’æ¤œå‡º"""
        main_files = []
        
        # ã‚¨ãƒ³ãƒˆãƒªãƒ¼ãƒã‚¤ãƒ³ãƒˆãƒ‘ã‚¿ãƒ¼ãƒ³
        entry_patterns = [
            'main.py', 'app.py', 'index.js', 'index.ts', 'main.go',
            'server.py', 'server.js', 'api.py', 'app.js'
        ]
        
        for pattern in entry_patterns:
            for file_path in project_path.rglob(pattern):
                if not any(ignored in str(file_path) for ignored in self.ignored_patterns):
                    main_files.append({
                        'path': str(file_path.relative_to(project_path)),
                        'type': 'entry_point',
                        'size': file_path.stat().st_size
                    })
        
        # è¨­å®šãƒ•ã‚¡ã‚¤ãƒ«
        config_patterns = [
            'config.py', 'settings.py', 'config.json', 'config.yaml',
            '.env.example', 'docker-compose.yml', 'Makefile'
        ]
        
        for pattern in config_patterns:
            for file_path in project_path.glob(pattern):
                if file_path.exists():
                    main_files.append({
                        'path': str(file_path.relative_to(project_path)),
                        'type': 'config',
                        'size': file_path.stat().st_size
                    })
        
        return main_files
    
    def _detect_services(self, project_path: Path) -> List[Dict]:
        """ãƒã‚¤ã‚¯ãƒ­ã‚µãƒ¼ãƒ“ã‚¹ã‚„APIã‚’æ¤œå‡º"""
        services = []
        
        # docker-compose.ymlã‹ã‚‰æŠ½å‡º
        compose_file = project_path / 'docker-compose.yml'
        if compose_file.exists():
            try:
                with open(compose_file, 'r', encoding='utf-8') as f:
                    content = yaml.safe_load(f)
                    if content and 'services' in content:
                        for service_name, config in content['services'].items():
                            services.append({
                                'name': service_name,
                                'type': 'docker',
                                'ports': config.get('ports', [])
                            })
            except Exception:
                pass
        
        # FastAPI/Flaskã‚¢ãƒ—ãƒªã‚’æ¤œå‡º
        for py_file in project_path.rglob('*.py'):
            if any(ignored in str(py_file) for ignored in self.ignored_patterns):
                continue
            
            try:
                with open(py_file, 'r', encoding='utf-8') as f:
                    content = f.read(1000)
                    if 'FastAPI()' in content or 'Flask(__name__)' in content:
                        services.append({
                            'name': py_file.stem,
                            'type': 'api',
                            'file': str(py_file.relative_to(project_path))
                        })
            except Exception:
                pass
        
        return services
    
    def _detect_databases(self, project_path: Path) -> List[str]:
        """ä½¿ç”¨ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹ã‚’æ¤œå‡º"""
        databases = set()
        
        # ç’°å¢ƒå¤‰æ•°ã‚„ã‚³ãƒ³ãƒ•ã‚£ã‚°ã‹ã‚‰æ¤œå‡º
        patterns = [
            ('DATABASE_URL', 'postgresql'),
            ('MONGO_URL', 'mongodb'),
            ('REDIS_URL', 'redis'),
            ('MYSQL_', 'mysql'),
            ('TIMESCALE', 'timescaledb')
        ]
        
        for file_name in ['.env', '.env.example', 'docker-compose.yml']:
            file_path = project_path / file_name
            if file_path.exists():
                try:
                    with open(file_path, 'r', encoding='utf-8') as f:
                        content = f.read()
                        for pattern, db_type in patterns:
                            if pattern in content:
                                databases.add(db_type)
                except Exception:
                    pass
        
        return list(databases)
    
    def _get_recent_changes(self, project_path: Path) -> List[Dict]:
        """æœ€è¿‘ã®å¤‰æ›´ã‚’å–å¾—"""
        changes = []
        
        try:
            # Git logã‹ã‚‰æœ€è¿‘ã®ã‚³ãƒŸãƒƒãƒˆã‚’å–å¾—
            result = subprocess.run(
                ['git', 'log', '--oneline', '-10'],
                cwd=project_path,
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line:
                        parts = line.split(' ', 1)
                        if len(parts) == 2:
                            changes.append({
                                'commit': parts[0],
                                'message': parts[1]
                            })
        except Exception:
            pass
        
        # æœ€è¿‘å¤‰æ›´ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«
        recent_files = []
        for file_path in project_path.rglob('*'):
            if file_path.is_file() and not any(ignored in str(file_path) for ignored in self.ignored_patterns):
                try:
                    mtime = file_path.stat().st_mtime
                    if mtime > (datetime.now().timestamp() - 86400):  # 24æ™‚é–“ä»¥å†…
                        recent_files.append({
                            'path': str(file_path.relative_to(project_path)),
                            'modified': datetime.fromtimestamp(mtime).isoformat()
                        })
                except Exception:
                    pass
        
        # æœ€æ–°5ãƒ•ã‚¡ã‚¤ãƒ«ã®ã¿
        recent_files.sort(key=lambda x: x['modified'], reverse=True)
        
        return {
            'commits': changes[:5],
            'files': recent_files[:5]
        }
    
    def _get_current_tasks(self, project_path: Path) -> List[Dict]:
        """ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯ã‚’å–å¾—"""
        tasks = []
        
        # .claude-task-cache.jsonã‹ã‚‰èª­ã¿è¾¼ã¿
        cache_file = project_path / '.claude-task-cache.json'
        if cache_file.exists():
            try:
                with open(cache_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    tasks.extend(data.get('tasks', []))
            except Exception:
                pass
        
        # TODO.mdã‹ã‚‰èª­ã¿è¾¼ã¿
        todo_file = project_path / 'TODO.md'
        if todo_file.exists():
            try:
                with open(todo_file, 'r', encoding='utf-8') as f:
                    lines = f.readlines()
                    for line in lines:
                        if line.strip().startswith('- [ ]'):
                            tasks.append({
                                'content': line.strip()[6:],
                                'status': 'pending',
                                'priority': 'medium'
                            })
            except Exception:
                pass
        
        return tasks
    
    def _analyze_dependencies(self, project_path: Path) -> Dict:
        """ä¾å­˜é–¢ä¿‚ã‚’åˆ†æ"""
        deps = {}
        
        # Python
        req_file = project_path / 'requirements.txt'
        if req_file.exists():
            try:
                with open(req_file, 'r', encoding='utf-8') as f:
                    deps['python'] = [line.strip() for line in f if line.strip() and not line.startswith('#')][:10]
            except Exception:
                pass
        
        # Node.js
        package_file = project_path / 'package.json'
        if package_file.exists():
            try:
                with open(package_file, 'r', encoding='utf-8') as f:
                    data = json.load(f)
                    deps['node'] = list(data.get('dependencies', {}).keys())[:10]
            except Exception:
                pass
        
        return deps
    
    def _get_test_status(self, project_path: Path) -> Dict:
        """ãƒ†ã‚¹ãƒˆçŠ¶æ…‹ã‚’å–å¾—"""
        status = {
            'passed': 0,
            'failed': 0,
            'skipped': 0
        }
        
        # pytestçµæœã‚’æ¢ã™
        for report_file in project_path.glob('**/pytest_*.xml'):
            # XMLãƒ‘ãƒ¼ã‚¹ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            try:
                with open(report_file, 'r', encoding='utf-8') as f:
                    content = f.read()
                    if 'failures=' in content:
                        # ç°¡æ˜“çš„ãªæŠ½å‡º
                        pass
            except Exception:
                pass
        
        return status
    
    def _get_docker_status(self, project_path: Path) -> List[Dict]:
        """Dockerã‚³ãƒ³ãƒ†ãƒŠã®çŠ¶æ…‹ã‚’å–å¾—"""
        containers = []
        
        try:
            result = subprocess.run(
                ['docker', 'ps', '--format', '{{.Names}}\t{{.Status}}\t{{.Ports}}'],
                capture_output=True,
                text=True,
                timeout=5
            )
            
            if result.returncode == 0:
                for line in result.stdout.strip().split('\n'):
                    if line:
                        parts = line.split('\t')
                        if len(parts) >= 2:
                            containers.append({
                                'name': parts[0],
                                'status': parts[1],
                                'ports': parts[2] if len(parts) > 2 else ''
                            })
        except Exception:
            pass
        
        return containers
    
    def filter_by_importance(self, state: Dict, max_tokens: int) -> Dict:
        """é‡è¦åº¦ã«åŸºã¥ã„ã¦ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°
        
        Args:
            state: ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŠ¶æ…‹
            max_tokens: æœ€å¤§ãƒˆãƒ¼ã‚¯ãƒ³æ•°
            
        Returns:
            ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸçŠ¶æ…‹
        """
        # Claude Codeç”¨ã®å„ªå…ˆé †ä½
        priority_config = self.config['knowledge_compression']['claude_code_optimization']['priority_order']
        
        filtered = {}
        estimated_tokens = 0
        
        # å„ªå…ˆé †ä½ã«å¾“ã£ã¦è¿½åŠ 
        priority_mapping = {
            'errors_and_issues': 'current_errors',
            'current_tasks': 'tasks',
            'recent_changes': 'recent_changes',
            'architecture_summary': 'architecture'
        }
        
        for priority_key in priority_config:
            if priority_key in priority_mapping:
                state_key = priority_mapping[priority_key]
                if state_key in state:
                    # ãƒˆãƒ¼ã‚¯ãƒ³æ•°ã‚’æ¨å®šï¼ˆç°¡æ˜“ç‰ˆ: 1æ–‡å­— = 0.25ãƒˆãƒ¼ã‚¯ãƒ³ï¼‰
                    content = json.dumps(state[state_key], ensure_ascii=False)
                    tokens = len(content) * 0.25
                    
                    if estimated_tokens + tokens <= max_tokens:
                        filtered[state_key] = state[state_key]
                        estimated_tokens += tokens
        
        # åŸºæœ¬æƒ…å ±ã¯å¸¸ã«å«ã‚ã‚‹
        filtered['project_info'] = state.get('project_info', {})
        
        return filtered
    
    def format_for_claude_code(self, state: Dict) -> str:
        """Claude Codeç”¨ã«ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ
        
        Args:
            state: ãƒ•ã‚£ãƒ«ã‚¿ãƒªãƒ³ã‚°ã•ã‚ŒãŸçŠ¶æ…‹
            
        Returns:
            Claude Codeç”¨ã«æœ€é©åŒ–ã•ã‚ŒãŸMarkdown
        """
        lines = [
            "# ğŸ§  ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçŸ¥è­˜ãƒãƒƒãƒ—ï¼ˆClaude Codeç”¨ï¼‰",
            "",
            "> ã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã¯ã€Claude CodeãŒåŠ¹ç‡çš„ã«é–‹ç™ºã™ã‚‹ãŸã‚ã®ã€Œåœ§ç¸®ã•ã‚ŒãŸçŸ¥è­˜ãƒ™ãƒ¼ã‚¹ã€ã§ã™ã€‚",
            "> å…¨ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã‚€ä»£ã‚ã‚Šã«ã€ã¾ãšã“ã®ãƒ•ã‚¡ã‚¤ãƒ«ã‚’èª­ã‚“ã§ãã ã•ã„ã€‚",
            ""
        ]
        
        # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæƒ…å ±
        if 'project_info' in state:
            info = state['project_info']
            lines.extend([
                "## ğŸ“ ç¾åœ¨åœ°",
                "",
                "### ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆæ¦‚è¦",
                f"- **åç§°**: {info.get('name', 'Unknown')}",
                f"- **ã‚¿ã‚¤ãƒ—**: {info.get('type', 'Unknown')}",
            ])
            if 'description' in info:
                lines.append(f"- **èª¬æ˜**: {info['description']}")
            lines.append("")
        
        # ç¾åœ¨ã®ã‚¨ãƒ©ãƒ¼ãƒ»å•é¡Œ
        if 'current_errors' in state and state['current_errors']:
            lines.extend([
                "### ğŸš¨ ç¾åœ¨ã®å•é¡Œ",
                "```yaml",
                "critical:"
            ])
            
            for error in state['current_errors'][:5]:
                lines.append(f"  - {error['type']}: {error['message'][:100]}")
            
            lines.extend(["", "```", ""])
        
        # ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£
        if 'architecture' in state:
            arch = state['architecture']
            lines.extend([
                "## ğŸ—ï¸ ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£",
                ""
            ])
            
            # ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ï¼ˆç°¡æ˜“ç‰ˆï¼‰
            if 'structure' in arch:
                lines.extend([
                    "### ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹é€ ï¼ˆé‡è¦éƒ¨åˆ†ã®ã¿ï¼‰",
                    "```"
                ])
                lines.extend(self._format_tree(arch['structure']))
                lines.extend(["```", ""])
            
            # ã‚µãƒ¼ãƒ“ã‚¹
            if 'services' in arch and arch['services']:
                lines.extend([
                    "### ä¸»è¦ã‚µãƒ¼ãƒ“ã‚¹",
                    "```yaml"
                ])
                for service in arch['services']:
                    lines.append(f"- {service['name']}: {service['type']}")
                lines.extend(["```", ""])
            
            # ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹
            if 'databases' in arch and arch['databases']:
                lines.append(f"### ãƒ‡ãƒ¼ã‚¿ãƒ™ãƒ¼ã‚¹: {', '.join(arch['databases'])}")
                lines.append("")
        
        # ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯
        if 'tasks' in state and state['tasks']:
            lines.extend([
                "## ğŸ¯ ç¾åœ¨ã®ã‚¿ã‚¹ã‚¯",
                ""
            ])
            
            # å„ªå…ˆåº¦åˆ¥ã«åˆ†é¡
            high_tasks = [t for t in state['tasks'] if t.get('priority') == 'high']
            medium_tasks = [t for t in state['tasks'] if t.get('priority') == 'medium']
            
            if high_tasks:
                lines.append("### ğŸ”´ High Priority")
                for task in high_tasks[:3]:
                    lines.append(f"- {task['content']}")
                lines.append("")
            
            if medium_tasks:
                lines.append("### ğŸŸ¡ Medium Priority")
                for task in medium_tasks[:3]:
                    lines.append(f"- {task['content']}")
                lines.append("")
        
        # æœ€è¿‘ã®å¤‰æ›´
        if 'recent_changes' in state:
            changes = state['recent_changes']
            lines.extend([
                "## ğŸ“ æœ€è¿‘ã®å¤‰æ›´",
                ""
            ])
            
            if 'commits' in changes and changes['commits']:
                lines.append("### æœ€æ–°ã‚³ãƒŸãƒƒãƒˆ")
                for commit in changes['commits'][:3]:
                    lines.append(f"- {commit['commit']}: {commit['message']}")
                lines.append("")
            
            if 'files' in changes and changes['files']:
                lines.append("### æœ€è¿‘æ›´æ–°ã•ã‚ŒãŸãƒ•ã‚¡ã‚¤ãƒ«")
                for file in changes['files'][:5]:
                    lines.append(f"- {file['path']} ({file['modified'][:10]})")
                lines.append("")
        
        # ãƒ•ãƒƒã‚¿ãƒ¼
        lines.extend([
            "---",
            f"æœ€çµ‚æ›´æ–°: {datetime.now().strftime('%Y-%m-%d %H:%M')}",
            "æ¬¡å›æ›´æ–°: `ukf knowledge compress` ã§å®Ÿè¡Œ"
        ])
        
        return '\n'.join(lines)
    
    def _format_tree(self, tree: Dict, prefix: str = "") -> List[str]:
        """ãƒ„ãƒªãƒ¼æ§‹é€ ã‚’ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        lines = []
        
        if tree['type'] == 'directory':
            lines.append(f"{prefix}{tree['name']}/")
            for i, child in enumerate(tree.get('children', [])):
                is_last = i == len(tree['children']) - 1
                child_prefix = prefix + ("â””â”€â”€ " if is_last else "â”œâ”€â”€ ")
                next_prefix = prefix + ("    " if is_last else "â”‚   ")
                
                if child['type'] == 'directory':
                    lines.extend(self._format_tree(child, child_prefix))
                else:
                    lines.append(f"{child_prefix}{child['name']}")
        
        return lines
    
    def format_as_mindmap(self, state: Dict) -> str:
        """ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—å½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        # TODO: ãƒã‚¤ãƒ³ãƒ‰ãƒãƒƒãƒ—å½¢å¼ã®å®Ÿè£…
        return "# Mind Map Format\n\nNot implemented yet."
    
    def format_as_markdown(self, state: Dict) -> str:
        """æ¨™æº–Markdownå½¢å¼ã§ãƒ•ã‚©ãƒ¼ãƒãƒƒãƒˆ"""
        return self.format_for_claude_code(state)  # æš«å®šçš„ã«åŒã˜å½¢å¼ã‚’ä½¿ç”¨
